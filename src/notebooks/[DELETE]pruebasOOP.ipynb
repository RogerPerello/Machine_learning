{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if str(os.getcwdb()[-3:]).split(\"'\")[1] != 'src':\n",
    "    os.chdir(os.path.dirname(os.getcwdb()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, f1_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "class Model:\n",
    "    chosen_models = dict()\n",
    "\n",
    "    def __init__(self, df, target_name, index=None):\n",
    "        self.target_name = target_name\n",
    "        self.index = index\n",
    "        self.df = df\n",
    "\n",
    "    @property\n",
    "    def dataframe(self):\n",
    "        if self.index:\n",
    "            return self.df.set_index(self.index)\n",
    "        else:\n",
    "            return self.df\n",
    "\n",
    "    @staticmethod\n",
    "    def send_pickle():\n",
    "        pass\n",
    "\n",
    "    def split_dataframe(self, train_num=0.7, random_num=43, scaler=None):\n",
    "        self.random_num = random_num\n",
    "        X = self.dataframe.drop(columns=self.target_name)\n",
    "        y = self.dataframe[self.target_name]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, train_size=train_num, random_state=self.random_num)\n",
    "        if scaler:\n",
    "            self.scaler = eval(scaler + '()')\n",
    "            self.scaler_name = ' (' + scaler + ')'\n",
    "            self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "            self.X_test = self.scaler.transform(self.X_test)        \n",
    "        else:\n",
    "            self.scaler_name = ''\n",
    "        return (self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "\n",
    "    def apply_models(self, selected_list=None, excluded_list=None, params_list=None):\n",
    "        self.models = self.chosen_models.copy()\n",
    "        if not excluded_list:\n",
    "            excluded_list = []\n",
    "        if not selected_list:\n",
    "            selected_list = []\n",
    "        current_time = time.time()\n",
    "        self.models_previous = self.models.copy()\n",
    "        for element in self.models_previous.keys():\n",
    "            if (len(selected_list) >= 1 and element not in selected_list) or element in excluded_list:\n",
    "                self.models.pop(element)\n",
    "        for model_name in self.models.keys():\n",
    "            self.models[model_name] = eval(model_name + '()')\n",
    "        if params_list:\n",
    "            for params in params_list:\n",
    "                self.models[params[0] + ': ' + params[1]] = eval(params[0] + '(' + params[1] + ')')\n",
    "            for params in params_list:\n",
    "                    if params[0] in self.models:\n",
    "                        try:\n",
    "                            self.models.pop(params[0])\n",
    "                        except Exception:\n",
    "                            continue\n",
    "        if self.kfolds_num:\n",
    "            print(f'-- {self.type.capitalize()}{self.scaler_name}: using best of {self.kfolds_num} {self.kfold}s --')\n",
    "        else:\n",
    "            print(f'-- {self.type.capitalize()} --')\n",
    "        total_time = time.time() - current_time\n",
    "        for model_name, model in self.models.items():\n",
    "            start_time = time.time()\n",
    "            print(f'Starting {model_name}:')\n",
    "            if self.kfolds_num:\n",
    "                score_string = 'accuracy'\n",
    "                if self.type == 'regression':\n",
    "                    score_string = 'neg_mean_absolute_error'\n",
    "                cross_val = cross_validate(model, self.X_train, self.y_train, cv=self.kfolds, return_estimator=True, scoring=score_string)\n",
    "                best_score = max(cross_val['test_score'])             \n",
    "                for index, element in enumerate(cross_val['test_score']):\n",
    "                    if element == best_score:\n",
    "                        best_score = index\n",
    "                model = cross_val['estimator'][best_score]\n",
    "            else:\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "            self.y_pred = model.predict(self.X_test)\n",
    "            self.models[model_name] = {'test': np.array(self.y_test), 'prediction': self.y_pred, 'model': model}\n",
    "            execution_time = time.time() - start_time\n",
    "            total_time += execution_time\n",
    "            print(f'- {model_name} done in {round(execution_time, 2)} sec(s). Total time: {round(total_time, 2)}')\n",
    "        return self.models\n",
    "\n",
    "    def evaluate_metrics(self, selection_list=None):\n",
    "        self.models_evaluated_previous = self.models\n",
    "        self.models_evaluated = copy(self.models_evaluated_previous)\n",
    "        if selection_list:\n",
    "            for element in self.models_evaluated_previous.keys():\n",
    "                if element not in selection_list:\n",
    "                    self.models_evaluated.pop(element)\n",
    "\n",
    "\n",
    "class Regression(Model):\n",
    "\n",
    "    def __init__(self, dataframe, target_name, index=None):\n",
    "        super().__init__(dataframe, target_name, index)\n",
    "        self.type = 'regression'\n",
    "\n",
    "    @classmethod\n",
    "    def add_models(cls, regression_list):\n",
    "        if regression_list:\n",
    "            for element in regression_list:\n",
    "                cls.chosen_models[element] = ''\n",
    "\n",
    "    @classmethod\n",
    "    def remove_models(cls, regression_list):\n",
    "        if regression_list:\n",
    "            for element in regression_list:\n",
    "                cls.chosen_models.pop(element)\n",
    "\n",
    "    def apply_models(self, selected_list=None, excluded_list=None, params_list=None, kfolds_num=None):\n",
    "        self.kfolds_num = kfolds_num\n",
    "        if kfolds_num:\n",
    "            self.kfolds = KFold(n_splits=kfolds_num, shuffle=True, random_state=self.random_num)\n",
    "            self.kfold = 'fold'\n",
    "        super().apply_models(selected_list, excluded_list, params_list)\n",
    "\n",
    "    def evaluate_metrics(self):\n",
    "        super().evaluate_metrics(selection_list=None)\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            rmse = mean_squared_error(model_results['test'], model_results['prediction'], squared=False)\n",
    "            mse = mean_squared_error(model_results['test'], model_results['prediction'])\n",
    "            mae = mean_absolute_error(model_results['test'], model_results['prediction'])\n",
    "            r2 = r2_score(model_results['test'], model_results['prediction'])\n",
    "            mape = mean_absolute_percentage_error(model_results['test'], model_results['prediction'])\n",
    "            self.models_evaluated[model_name]['metrics'] = {'rmse': rmse, 'mse': mse, 'mae': mae, 'r2_score': r2, 'mape': mape}\n",
    "        return self.models_evaluated\n",
    "\n",
    "    def create_dataframe(self):\n",
    "        self.models_metrics = self.models_evaluated.copy()\n",
    "        metrics_list = []\n",
    "        best_values_list = []\n",
    "        worst_values_list = []\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            self.models_metrics[model_name] = self.models_metrics[model_name]['metrics']\n",
    "            model_values = [value if type(value) is not list else sum([row[index] for index, row in enumerate(value)]) for value in self.models_evaluated[model_name]['metrics'].values()]\n",
    "            if not metrics_list:\n",
    "                metrics_list += [key for key in self.models_evaluated[model_name]['metrics'].keys()]\n",
    "            if not best_values_list:\n",
    "                best_values_list = [[model_name, value] for value in model_values]\n",
    "                worst_values_list = [[model_name, value] for value in model_values]\n",
    "            else:\n",
    "                for index, value in enumerate(model_values):\n",
    "                    if value < best_values_list[index][1]:\n",
    "                        if index != 3:\n",
    "                            best_values_list[index][1] = value\n",
    "                            best_values_list[index][0] = model_name\n",
    "                        else:\n",
    "                            worst_values_list[index][1] = value\n",
    "                            worst_values_list[index][0] = model_name\n",
    "                    if value > worst_values_list[index][1]:\n",
    "                        if index != 3:\n",
    "                            worst_values_list[index][1] = value\n",
    "                            worst_values_list[index][0] = model_name\n",
    "                        else:\n",
    "                            best_values_list[index][1] = value\n",
    "                            best_values_list[index][0] = model_name\n",
    "        df = pd.DataFrame(data=self.models_metrics)\n",
    "        best_values_list = [element[0] for element in best_values_list]\n",
    "        worst_values_list = [element[0] for element in worst_values_list]\n",
    "        df['BEST'] = best_values_list\n",
    "        df['WORST'] = worst_values_list\n",
    "        return df\n",
    "\n",
    "\n",
    "class Classification(Model):\n",
    "\n",
    "    def __init__(self, dataframe, target_name, index=None):\n",
    "        super().__init__(dataframe, target_name, index)\n",
    "        self.type = 'classification'\n",
    "\n",
    "    @classmethod\n",
    "    def add_models(cls, classification_list):\n",
    "        if classification_list:\n",
    "            for element in classification_list:\n",
    "                cls.chosen_models[element] = ''\n",
    "\n",
    "    @classmethod\n",
    "    def remove_models(cls, classification_list):\n",
    "        if classification_list:\n",
    "            for element in classification_list:\n",
    "                cls.chosen_models.pop(element)\n",
    "\n",
    "    def apply_models(self, selected_list=None, excluded_list=None, params_list=None, kfolds_num=None):\n",
    "        if kfolds_num:\n",
    "            self.kfolds = StratifiedKFold(n_splits=kfolds_num, shuffle=True, random_state=self.random_num)\n",
    "            self.kfolds_num = kfolds_num\n",
    "            self.kfold = 'stratified fold'\n",
    "        super().apply_models(selected_list, excluded_list, params_list)\n",
    "\n",
    "    def evaluate_metrics(self, params_list=None):\n",
    "        super().evaluate_metrics(selection_list=None)\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            accuracy = \"accuracy_score (model_results['test'], model_results['prediction']\"\n",
    "            recall = \"recall_score (model_results['test'], model_results['prediction']\"\n",
    "            precision = \"precision_score (model_results['test'], model_results['prediction']\"\n",
    "            f1 = \"f1_score (model_results['test'], model_results['prediction']\"\n",
    "            matrix = \"confusion_matrix (model_results['test'], model_results['prediction']\"\n",
    "            list_of_metrics = []\n",
    "            for element in (accuracy, recall, precision, f1, matrix):\n",
    "                if params_list:\n",
    "                    for params in params_list:\n",
    "                        if params[0] == element.split()[0]:\n",
    "                            list_of_metrics.append(eval(element + \",\" + params[1] + \")\"))\n",
    "                        else:\n",
    "                            list_of_metrics.append(eval(element + \")\"))\n",
    "                            continue\n",
    "                else:\n",
    "                    list_of_metrics.append(eval(element + \")\"))\n",
    "            confusion = [element for element in list_of_metrics[-1]]\n",
    "            self.models_evaluated[model_name]['metrics'] = {'accuracy': list_of_metrics[0], 'recall': list_of_metrics[1], 'precision': list_of_metrics[2], 'f1_score': list_of_metrics[3], 'confusion_matrix': confusion}\n",
    "        return self.models_evaluated\n",
    "\n",
    "    def create_dataframe(self):\n",
    "        self.models_metrics = self.models_evaluated.copy()\n",
    "        metrics_list = []\n",
    "        best_values_list = []\n",
    "        worst_values_list = []\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            self.models_metrics[model_name] = self.models_metrics[model_name]['metrics']\n",
    "            model_values = [value if type(value) is not list else sum([row[index] for index, row in enumerate(value)]) for value in self.models_evaluated[model_name]['metrics'].values()]\n",
    "            if not metrics_list:\n",
    "                metrics_list += [key for key in self.models_evaluated[model_name]['metrics'].keys()]\n",
    "            if not best_values_list:\n",
    "                best_values_list = [[model_name, value] for value in model_values]\n",
    "                worst_values_list = [[model_name, value] for value in model_values]\n",
    "            else:\n",
    "                for index, value in enumerate(model_values):\n",
    "                    if value > best_values_list[index][1]:\n",
    "                        best_values_list[index][1] = value\n",
    "                        best_values_list[index][0] = model_name\n",
    "                    if value < worst_values_list[index][1]:\n",
    "                        worst_values_list[index][1] = value\n",
    "                        worst_values_list[index][0] = model_name\n",
    "        df = pd.DataFrame(data=self.models_metrics)\n",
    "        best_values_list = [element[0] for element in best_values_list]\n",
    "        worst_values_list = [element[0] for element in worst_values_list]\n",
    "        df['BEST'] = best_values_list\n",
    "        df['WORST'] = worst_values_list\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class Cleansing:\n",
    "\n",
    "    def __init__(self, dataframes, target_name, index=None):\n",
    "        self.train = dataframes[0]\n",
    "        self.test = dataframes[1]\n",
    "        self.target_name = target_name\n",
    "        self.target = self.train[target_name]\n",
    "        if index:\n",
    "            self.train = self.train.set_index(index)\n",
    "            self.test = self.test.set_index(index)\n",
    "\n",
    "    def impute_boxplot_min_max(self, list_of_columns, min=True, max=True):\n",
    "        '''Imputes the outliers of a boxplot for the chosen columns to its min and max values'''\n",
    "        for column in list_of_columns:\n",
    "            q3, q1 = np.percentile(self.train[column], [75, 25])\n",
    "            iqr = q3 - q1\n",
    "            if min:\n",
    "                self.train.loc[self.train[column] < q1 - 1.5*iqr, column] = q1 - 1.5*iqr\n",
    "            if max:\n",
    "                self.train.loc[self.train[column] > q3 + 1.5*iqr, column] = q3 + 1.5*iqr\n",
    "        return self.train\n",
    "\n",
    "    def remove_elements(self, conditioned_columns_list, condition, number):\n",
    "        '''Removes the rows of a dataframe based on a condition'''\n",
    "        for column in conditioned_columns_list:\n",
    "            if condition == 'equal':\n",
    "                self.train.drop(self.train[(self.train[column] == number)].index, inplace=True)\n",
    "            elif condition == 'bigger':\n",
    "                self.train.drop(self.train[(self.train[column] > number)].index, inplace=True)\n",
    "            elif condition == 'bigger_or_equal':\n",
    "                self.train.drop(self.train[(self.train[column] >= number)].index, inplace=True)   \n",
    "            elif condition == 'smaller':\n",
    "                self.train.drop(self.train[(self.train[column] < number)].index, inplace=True)   \n",
    "            elif condition == 'smaller_or_equal':\n",
    "                self.train.drop(self.train[(self.train[column] <= number)].index, inplace=True)\n",
    "            return self.train\n",
    "\n",
    "    def apply_scalar(self, method, list_of_columns=None):\n",
    "        '''Applies the selected scalar method to a list of train and test dataframes for the chosen columns'''\n",
    "        scaled_train = self.train.copy()\n",
    "        scaled_test = self.test.copy()\n",
    "        if method == 'log' and list_of_columns:\n",
    "            for df in (scaled_train, scaled_test):\n",
    "                for column in list_of_columns:\n",
    "                    df[column] = np.log(df[column])\n",
    "        elif method == 'standard':\n",
    "            scaler = StandardScaler().fit(scaled_train.values)\n",
    "            scaled_test = scaled_test.join(self.target)\n",
    "            for df in (scaled_train, scaled_test):\n",
    "                df.loc[:, :] = scaler.transform(df.values)\n",
    "            scaled_test = scaled_test.drop(columns=self.target_name)\n",
    "        elif method == 'minmax':\n",
    "            scaler = MinMaxScaler().fit(scaled_train.values)\n",
    "            scaled_test = scaled_test.join(self.target)\n",
    "            for df in (scaled_train, scaled_test):\n",
    "                df.loc[:, :] = scaler.transform(df.values)\n",
    "            scaled_test = scaled_test.drop(columns=self.target_name)\n",
    "        return (scaled_train, scaled_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamonds = pd.read_csv(r'data\\processed\\diamonds_training.csv', index_col='id')\n",
    "df_predict = pd.read_csv(r'data\\processed\\diamonds_testing.csv', index_col='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression.add_models(['LinearRegression',\n",
    "                        'XGBRegressor'\n",
    "                        ]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_1 = Regression(df_diamonds, 'price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       weight (carat)  cut quality  color quality  clarity quality  \\\n",
       " id                                                                   \n",
       " 26690            1.38          1.0            0.0              1.0   \n",
       " 15750            0.70          4.0            4.0              2.0   \n",
       " 37107            1.51          4.0            0.0              5.0   \n",
       " 34550            0.23          2.0            4.0              7.0   \n",
       " 31691            1.50          3.0            3.0              2.0   \n",
       " ...               ...          ...            ...              ...   \n",
       " 5307             1.56          2.0            4.0              2.0   \n",
       " 25233            1.53          4.0            2.0              2.0   \n",
       " 18448            0.52          2.0            4.0              2.0   \n",
       " 19776            1.20          1.0            3.0              3.0   \n",
       " 14148            1.73          3.0            2.0              3.0   \n",
       " \n",
       "        depth (percentage)  table (percentage)  lenght (millimeters)  \\\n",
       " id                                                                    \n",
       " 26690                63.7                58.0                  7.06   \n",
       " 15750                61.6                55.0                  5.72   \n",
       " 37107                61.4                59.0                  7.34   \n",
       " 34550                61.0                62.0                  3.95   \n",
       " 31691                60.2                61.0                  7.28   \n",
       " ...                   ...                 ...                   ...   \n",
       " 5307                 61.0                58.0                  7.41   \n",
       " 25233                59.8                59.0                  7.48   \n",
       " 18448                62.3                55.0                  5.14   \n",
       " 19776                57.8                59.0                  7.06   \n",
       " 14148                59.2                61.0                  7.82   \n",
       " \n",
       "        width (millimeters)  depth (millimeters)  \n",
       " id                                               \n",
       " 26690                 7.01                 4.48  \n",
       " 15750                 5.74                 3.53  \n",
       " 37107                 7.39                 4.52  \n",
       " 34550                 3.99                 2.42  \n",
       " 31691                 7.20                 4.36  \n",
       " ...                    ...                  ...  \n",
       " 5307                  7.48                 4.54  \n",
       " 25233                 7.54                 4.49  \n",
       " 18448                 5.17                 3.21  \n",
       " 19776                 7.00                 4.06  \n",
       " 14148                 7.78                 4.62  \n",
       " \n",
       " [28318 rows x 9 columns],\n",
       "        weight (carat)  cut quality  color quality  clarity quality  \\\n",
       " id                                                                   \n",
       " 35681            0.91          2.0            4.0              2.0   \n",
       " 26396            1.13          4.0            3.0              5.0   \n",
       " 13244            0.90          1.0            4.0              1.0   \n",
       " 15733            1.02          4.0            2.0              1.0   \n",
       " 7677             1.10          4.0            3.0              5.0   \n",
       " ...               ...          ...            ...              ...   \n",
       " 14135            1.01          3.0            6.0              2.0   \n",
       " 21593            0.24          2.0            5.0              3.0   \n",
       " 14353            1.51          3.0            3.0              2.0   \n",
       " 20300            1.27          3.0            2.0              3.0   \n",
       " 10066            0.90          3.0            3.0              3.0   \n",
       " \n",
       "        depth (percentage)  table (percentage)  lenght (millimeters)  \\\n",
       " id                                                                    \n",
       " 35681                63.3                60.0                  6.10   \n",
       " 26396                61.5                57.0                  6.67   \n",
       " 13244                61.9                59.0                  6.09   \n",
       " 15733                62.4                55.0                  6.41   \n",
       " 7677                 61.0                56.0                  6.69   \n",
       " ...                   ...                 ...                   ...   \n",
       " 14135                62.8                60.0                  6.42   \n",
       " 21593                62.1                58.0                  4.00   \n",
       " 14353                62.5                60.0                  7.28   \n",
       " 20300                62.6                59.0                  6.83   \n",
       " 10066                61.5                60.0                  6.16   \n",
       " \n",
       "        width (millimeters)  depth (millimeters)  \n",
       " id                                               \n",
       " 35681                 6.06                 3.85  \n",
       " 26396                 6.71                 4.12  \n",
       " 13244                 6.12                 3.78  \n",
       " 15733                 6.46                 4.02  \n",
       " 7677                  6.73                 4.09  \n",
       " ...                    ...                  ...  \n",
       " 14135                 6.36                 4.01  \n",
       " 21593                 4.02                 2.49  \n",
       " 14353                 7.32                 4.56  \n",
       " 20300                 6.93                 4.31  \n",
       " 10066                 6.13                 3.78  \n",
       " \n",
       " [12137 rows x 9 columns],\n",
       " id\n",
       " 26690    8.433\n",
       " 15750    7.940\n",
       " 37107    9.141\n",
       " 34550    6.184\n",
       " 31691    9.232\n",
       "          ...  \n",
       " 5307     9.410\n",
       " 25233    9.217\n",
       " 18448    7.112\n",
       " 19776    8.991\n",
       " 14148    9.490\n",
       " Name: price, Length: 28318, dtype: float64,\n",
       " id\n",
       " 35681    8.069\n",
       " 26396    9.093\n",
       " 13244    8.297\n",
       " 15733    8.491\n",
       " 7677     9.196\n",
       "          ...  \n",
       " 14135    8.689\n",
       " 21593    6.038\n",
       " 14353    9.234\n",
       " 20300    8.818\n",
       " 10066    8.368\n",
       " Name: price, Length: 12137, dtype: float64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_1.split_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Regression: using best of 10 folds --\n",
      "Starting LinearRegression:\n",
      "- LinearRegression done in 0.42 sec(s). Total time: 0.42\n",
      "Starting XGBRegressor: random_state=43:\n",
      "- XGBRegressor: random_state=43 done in 12.74 sec(s). Total time: 13.16\n"
     ]
    }
   ],
   "source": [
    "round_1.apply_models(params_list=[['XGBRegressor', 'random_state=43']], kfolds_num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.1751789 , 8.94534424, 7.94609508, ..., 9.13303572, 8.78005708,\n",
       "         8.22465851]),\n",
       "  'model': LinearRegression(),\n",
       "  'metrics': {'rmse': 0.222037823248969,\n",
       "   'mse': 0.0493007949531404,\n",
       "   'mae': 0.12289980638635319,\n",
       "   'r2_score': 0.9529090797126748,\n",
       "   'mape': 0.01587291534328809}},\n",
       " 'XGBRegressor: random_state=43': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.279677, 9.100804, 8.133977, ..., 9.290244, 8.891319, 8.354892],\n",
       "        dtype=float32),\n",
       "  'model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=43, ...),\n",
       "  'metrics': {'rmse': 0.09340840203389687,\n",
       "   'mse': 0.008725129570526109,\n",
       "   'mae': 0.06631705023042744,\n",
       "   'r2_score': 0.9916659684393982,\n",
       "   'mape': 0.008557595151799378}}}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_1.evaluate_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>XGBRegressor: random_state=43</th>\n",
       "      <th>BEST</th>\n",
       "      <th>WORST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.222038</td>\n",
       "      <td>0.093408</td>\n",
       "      <td>XGBRegressor: random_state=43</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>XGBRegressor: random_state=43</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.066317</td>\n",
       "      <td>XGBRegressor: random_state=43</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>0.952909</td>\n",
       "      <td>0.991666</td>\n",
       "      <td>XGBRegressor: random_state=43</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>XGBRegressor: random_state=43</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LinearRegression  XGBRegressor: random_state=43  \\\n",
       "rmse              0.222038                       0.093408   \n",
       "mse               0.049301                       0.008725   \n",
       "mae               0.122900                       0.066317   \n",
       "r2_score          0.952909                       0.991666   \n",
       "mape              0.015873                       0.008558   \n",
       "\n",
       "                                   BEST             WORST  \n",
       "rmse      XGBRegressor: random_state=43  LinearRegression  \n",
       "mse       XGBRegressor: random_state=43  LinearRegression  \n",
       "mae       XGBRegressor: random_state=43  LinearRegression  \n",
       "r2_score  XGBRegressor: random_state=43  LinearRegression  \n",
       "mape      XGBRegressor: random_state=43  LinearRegression  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_1.create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': '', 'XGBRegressor': ''}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_2 = Regression(df_diamonds, 'price')\n",
    "\n",
    "round_2.chosen_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62be4b4d7aada9f05487a097e316e83dc3ceda15568e9d0ea281b513767b88d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
