{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if str(os.getcwdb()[-3:]).split(\"'\")[1] != 'src':\n",
    "    os.chdir(os.path.dirname(os.getcwdb()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_validate\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, f1_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "\n",
    "    def __init__(self, df, target_name, index=None):\n",
    "        self.target_name = target_name\n",
    "        self.index = index\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    @property\n",
    "    def dataframe(self):\n",
    "        if self.index:\n",
    "            return self.df.set_index(self.index)\n",
    "        else:\n",
    "            return self.df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def send_pickle():\n",
    "        pass\n",
    "\n",
    "\n",
    "    def split_dataframe(self, train_num=0.7, random_num=43, scaler=None, return_entire_Xy=False):\n",
    "        self.random_num = random_num\n",
    "        X = self.dataframe.drop(columns=self.target_name)\n",
    "        y = self.dataframe[self.target_name]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, train_size=train_num, random_state=self.random_num)\n",
    "        if scaler:\n",
    "            self.scaler = eval(scaler + '()')\n",
    "            self.scaler_name = ' (' + scaler + ')'\n",
    "            self.X_train = self.scaler.fit_transform(self.X_train)\n",
    "            self.X_test = self.scaler.transform(self.X_test)        \n",
    "            if return_entire_Xy:\n",
    "                self.scaler = eval(scaler + '()')\n",
    "                X = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            self.scaler_name = ''\n",
    "        if return_entire_Xy:\n",
    "            return (X, y)\n",
    "        else:\n",
    "            return (self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "\n",
    "\n",
    "    def prepare_models(self, selected_list=None, excluded_list=None, params_list=None):\n",
    "        self.models = self.chosen_models.copy()\n",
    "        if not excluded_list:\n",
    "            excluded_list = []\n",
    "        if not selected_list:\n",
    "            selected_list = []\n",
    "        self.models_previous = self.models.copy()\n",
    "        for element in self.models_previous.keys():\n",
    "            if (len(selected_list) >= 1 and element not in selected_list) or element in excluded_list:\n",
    "                self.models.pop(element)\n",
    "        for model_name in self.models.keys():\n",
    "            self.models[model_name] = eval(model_name + '()')\n",
    "        if params_list:\n",
    "            for params in params_list:\n",
    "                self.models[params[0] + ': ' + params[1]] = eval(params[0] + '(' + params[1] + ')')\n",
    "            for params in params_list:\n",
    "                    if params[0] in self.models:\n",
    "                        try:\n",
    "                            self.models.pop(params[0])\n",
    "                        except Exception:\n",
    "                            continue\n",
    "        return 'Models prepared. Apply them or use kfold (apply + evaluate)'\n",
    "\n",
    "\n",
    "    def apply_models(self):\n",
    "        print(f'-- {self.type.capitalize()} --')\n",
    "        current_time = time.time()\n",
    "        total_time = time.time() - current_time\n",
    "        for model_name, model in self.models.items():\n",
    "            start_time = time.time()\n",
    "            print(f'Starting {model_name}:')\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            self.y_pred = model.predict(self.X_test)\n",
    "            self.models[model_name] = {'test': np.array(self.y_test), 'prediction': self.y_pred, 'model': model}\n",
    "            execution_time = time.time() - start_time\n",
    "            total_time += execution_time\n",
    "            print(f'- {model_name} done in {round(execution_time, 2)} sec(s). Total time: {round(total_time, 2)}')\n",
    "        return self.models\n",
    "\n",
    "\n",
    "    def create_dataframe(self, best_values_list, worst_values_list):\n",
    "        self.df = pd.DataFrame(data=self.models_metrics)\n",
    "        if best_values_list:\n",
    "            best_values_list = [element[0] for element in best_values_list]\n",
    "            worst_values_list = [element[0] for element in worst_values_list]\n",
    "            self.df['BEST'] = best_values_list\n",
    "            self.df['WORST'] = worst_values_list\n",
    "\n",
    "\n",
    "    def visualize(self, metrics_selection=None):\n",
    "        visualization_dict = {'models': [model_name for model_name in self.models_metrics.keys() for metric in self.models_metrics[model_name] if (not metrics_selection or metric in metrics_selection)],\n",
    "                              'metrics': [metric for model_name in self.models_metrics.keys() for metric in self.models_metrics[model_name] if (not metrics_selection or metric in metrics_selection)],\n",
    "                              'values': [self.models_metrics[model_name][metric] for model_name in self.models_metrics.keys() for metric in self.models_metrics[model_name] if (not metrics_selection or metric in metrics_selection)]\n",
    "                              }\n",
    "        sns.lineplot(data=visualization_dict, x='models', y='values', hue='metrics')\n",
    "        plt.tick_params(axis='x', labelrotation = 30)\n",
    "        plt.title('Medicine price by date')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "class Regression(Model):\n",
    "    chosen_models = dict()\n",
    "\n",
    "\n",
    "    def __init__(self, dataframe, target_name, index=None):\n",
    "        super().__init__(dataframe, target_name, index)\n",
    "        self.type = 'regression'\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def add_models(cls, regression_list):\n",
    "        if regression_list:\n",
    "            for element in regression_list:\n",
    "                cls.chosen_models[element] = ''\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def remove_models(cls, regression_list):\n",
    "        if regression_list:\n",
    "            for element in regression_list:\n",
    "                cls.chosen_models.pop(element)\n",
    "\n",
    "  \n",
    "    def apply_and_evaluate_kfolds(self, kfolds_num=5):\n",
    "        self.kfolds_num = kfolds_num\n",
    "        self.kfolds = KFold(n_splits=kfolds_num, shuffle=True, random_state=self.random_num)\n",
    "        self.kfold = 'fold'\n",
    "        metrics = ['neg_root_mean_squared_error', 'neg_mean_squared_error', 'neg_mean_absolute_error', 'r2', 'neg_mean_absolute_percentage_error']\n",
    "        self.models_evaluated = dict()\n",
    "        print(f'-- {self.type.capitalize()}{self.scaler_name}: using mean of {self.kfolds_num} {self.kfold}s --')\n",
    "        current_time = time.time()\n",
    "        total_time = time.time() - current_time\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f'Starting {model_name}:')\n",
    "            start_time = time.time()\n",
    "            cross_val = cross_validate(model, self.X_train, self.y_train, cv=self.kfolds, return_estimator=True, scoring=metrics)\n",
    "            list_of_metrics = list(cross_val.keys())[3:]\n",
    "            self.models_evaluated[model_name] = dict()\n",
    "            self.models_evaluated[model_name]['models'] = cross_val['estimator']\n",
    "            self.models_evaluated[model_name]['metrics'] = {'rmse': abs(np.mean(list(cross_val.values())[3:][0])), \n",
    "                                                            'mse': abs(np.mean(list(cross_val.values())[3:][1])), \n",
    "                                                            'mae': abs(np.mean(list(cross_val.values())[3:][2])), \n",
    "                                                            'r2_score': np.mean(list(cross_val.values())[3:][3]), \n",
    "                                                            'mape': abs(np.mean(list(cross_val.values())[3:][4]))}\n",
    "            self.models_evaluated[model_name]['all_metrics'] = {'rmse': list(map(abs, list(cross_val.values())[3:][0])), \n",
    "                                                            'mse': list(map(abs, list(cross_val.values())[3:][1])), \n",
    "                                                            'mae': list(map(abs, list(cross_val.values())[3:][2])), \n",
    "                                                            'r2_score': list(map(abs, list(cross_val.values())[3:][3])), \n",
    "                                                            'mape': list(map(abs, list(cross_val.values())[3:][4]))}\n",
    "            self.models_evaluated[model_name]['variances'] = {'rmse': np.var(list(cross_val.values())[3:][0]), \n",
    "                                                            'mse': np.var(list(cross_val.values())[3:][1]), \n",
    "                                                            'mae': np.var(list(cross_val.values())[3:][2]), \n",
    "                                                            'r2_score': np.var(list(cross_val.values())[3:][3]), \n",
    "                                                            'mape': np.var(list(cross_val.values())[3:][4])}\n",
    "            execution_time = time.time() - start_time\n",
    "            total_time += execution_time\n",
    "            print(f'- {model_name} done in {round(execution_time, 2)} sec(s). Total time: {round(total_time, 2)}')\n",
    "        return self.models_evaluated\n",
    "\n",
    "\n",
    "    def evaluate_metrics(self):\n",
    "        self.models_evaluated = self.models.copy()\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            rmse = mean_squared_error(model_results['test'], model_results['prediction'], squared=False)\n",
    "            mse = mean_squared_error(model_results['test'], model_results['prediction'])\n",
    "            mae = mean_absolute_error(model_results['test'], model_results['prediction'])\n",
    "            r2 = r2_score(model_results['test'], model_results['prediction'])\n",
    "            mape = mean_absolute_percentage_error(model_results['test'], model_results['prediction'])\n",
    "            self.models_evaluated[model_name]['metrics'] = {'rmse': rmse, 'mse': mse, 'mae': mae, 'r2_score': r2, 'mape': mape}\n",
    "        return self.models_evaluated\n",
    "\n",
    "\n",
    "    def create_dataframe(self, chosen_metric='mean'):\n",
    "        self.models_metrics = self.models_evaluated.copy()\n",
    "        best_values_list = []\n",
    "        worst_values_list = []\n",
    "        if chosen_metric == 'mean':\n",
    "            chosen_metric = 'metrics'\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            self.models_metrics[model_name] = self.models_metrics[model_name][chosen_metric]\n",
    "            if len(self.models_metrics) > 1:\n",
    "                model_values = [value if type(value) is not list else sum([row[index] for index, row in enumerate(value)]) for value in self.models_evaluated[model_name][chosen_metric].values()]\n",
    "                if not best_values_list:\n",
    "                    best_values_list = [[model_name, value] for value in model_values]\n",
    "                    worst_values_list = [[model_name, value] for value in model_values]\n",
    "                else:\n",
    "                    for index, value in enumerate(model_values):\n",
    "                        if value < best_values_list[index][1]:\n",
    "                            if index != 3:\n",
    "                                best_values_list[index][1] = value\n",
    "                                best_values_list[index][0] = model_name\n",
    "                            else:\n",
    "                                worst_values_list[index][1] = value\n",
    "                                worst_values_list[index][0] = model_name\n",
    "                        if value > worst_values_list[index][1]:\n",
    "                            if index != 3:\n",
    "                                worst_values_list[index][1] = value\n",
    "                                worst_values_list[index][0] = model_name\n",
    "                            else:\n",
    "                                best_values_list[index][1] = value\n",
    "                                best_values_list[index][0] = model_name\n",
    "        super().create_dataframe(best_values_list, worst_values_list)\n",
    "        return self.df\n",
    "\n",
    "\n",
    "\n",
    "class Classification(Model):\n",
    "    chosen_models = dict()\n",
    "\n",
    "\n",
    "    def __init__(self, dataframe, target_name, index=None):\n",
    "        super().__init__(dataframe, target_name, index)\n",
    "        self.type = 'classification'\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def add_models(cls, classification_list):\n",
    "        if classification_list:\n",
    "            for element in classification_list:\n",
    "                cls.chosen_models[element] = ''\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def remove_models(cls, classification_list):\n",
    "        if classification_list:\n",
    "            for element in classification_list:\n",
    "                cls.chosen_models.pop(element)\n",
    "\n",
    "\n",
    "    def apply_and_evaluate_kfolds(self, kfolds_num=5, multiclass_average=None):\n",
    "        self.kfolds = StratifiedKFold(n_splits=kfolds_num, shuffle=True, random_state=self.random_num)\n",
    "        self.kfolds_num = kfolds_num\n",
    "        self.kfold = 'stratified fold'\n",
    "        metrics = ['accuracy', 'recall', 'precision', 'f1']\n",
    "        if multiclass_average == 'micro':\n",
    "            metrics = ['accuracy', 'precision_micro', 'recall_micro', 'f1_micro'] \n",
    "        elif multiclass_average == 'macro':\n",
    "            metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'] \n",
    "        elif multiclass_average == 'samples':\n",
    "            metrics = ['accuracy', 'precision_samples', 'recall_samples', 'f1_samples'] \n",
    "        elif multiclass_average == 'weighted':\n",
    "            metrics = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'] \n",
    "        self.models_evaluated = dict()\n",
    "        print(f'-- {self.type.capitalize()}{self.scaler_name}: using mean of {self.kfolds_num} {self.kfold}s --')\n",
    "        current_time = time.time()\n",
    "        total_time = time.time() - current_time\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f'Starting {model_name}:')\n",
    "            start_time = time.time()\n",
    "            cross_val = cross_validate(model, self.X_train, self.y_train, cv=self.kfolds, return_estimator=True, scoring=metrics)\n",
    "            self.models_evaluated[model_name] = dict()\n",
    "            self.models_evaluated[model_name]['models'] = cross_val['estimator']\n",
    "            self.models_evaluated[model_name]['metrics'] = {'accuracy': abs(np.mean(list(cross_val.values())[3:][0])), \n",
    "                                                            'recall': abs(np.mean(list(cross_val.values())[3:][1])), \n",
    "                                                            'precision': abs(np.mean(list(cross_val.values())[3:][2])), \n",
    "                                                            'f1_score': np.mean(list(cross_val.values())[3:][3])}\n",
    "            self.models_evaluated[model_name]['all_metrics'] = {'accuracy': list(map(abs, list(cross_val.values())[3:][0])), \n",
    "                                                            'recall': list(map(abs, list(cross_val.values())[3:][1])), \n",
    "                                                            'precision': list(map(abs, list(cross_val.values())[3:][2])), \n",
    "                                                            'f1_score': list(map(abs, list(cross_val.values())[3:][3]))}\n",
    "            self.models_evaluated[model_name]['variances'] = {'accuracy': np.var(list(cross_val.values())[3:][0]), \n",
    "                                                            'recall': np.var(list(cross_val.values())[3:][1]), \n",
    "                                                            'precision': np.var(list(cross_val.values())[3:][2]), \n",
    "                                                            'f1_score': np.var(list(cross_val.values())[3:][3])}\n",
    "            execution_time = time.time() - start_time\n",
    "            total_time += execution_time\n",
    "            print(f'- {model_name} done in {round(execution_time, 2)} sec(s). Total time: {round(total_time, 2)}')\n",
    "        return self.models_evaluated\n",
    "\n",
    "\n",
    "    def evaluate_metrics(self, params_list=None):\n",
    "        self.models_evaluated = self.models.copy()\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            accuracy = \"accuracy_score (model_results['test'], model_results['prediction']\"\n",
    "            recall = \"recall_score (model_results['test'], model_results['prediction']\"\n",
    "            precision = \"precision_score (model_results['test'], model_results['prediction']\"\n",
    "            f1 = \"f1_score (model_results['test'], model_results['prediction']\"\n",
    "            matrix = \"confusion_matrix (model_results['test'], model_results['prediction']\"\n",
    "            list_of_metrics = []\n",
    "            for index, element in enumerate([accuracy, recall, precision, f1, matrix], 1):\n",
    "                if params_list:\n",
    "                    for params in params_list:\n",
    "                        if params[0] == element.split()[0]:\n",
    "                            element += ', ' + params[1] + ')'\n",
    "                if element[-1] == ']':\n",
    "                    element += ')'\n",
    "                list_of_metrics.append(eval(element))\n",
    "            print(list_of_metrics)\n",
    "            confusion = [element for element in list_of_metrics[-1]]\n",
    "            self.models_evaluated[model_name]['metrics'] = {'accuracy': list_of_metrics[0], 'recall': list_of_metrics[1], 'precision': list_of_metrics[2], 'f1_score': list_of_metrics[3], 'confusion_matrix': confusion}\n",
    "        return self.models_evaluated\n",
    "\n",
    "\n",
    "    def create_dataframe(self, chosen_metric='mean'):\n",
    "        self.models_metrics = self.models_evaluated.copy()\n",
    "        best_values_list = []\n",
    "        worst_values_list = []\n",
    "        if chosen_metric == 'mean':\n",
    "            chosen_metric = 'metrics'\n",
    "        for model_name, model_results in self.models_evaluated.items():\n",
    "            self.models_metrics[model_name] = self.models_metrics[model_name][chosen_metric]\n",
    "            if len(self.models_metrics) > 1:\n",
    "                model_values = [value if type(value) is not list else sum([row[index] for index, row in enumerate(value)]) for value in self.models_evaluated[model_name][chosen_metric].values()]\n",
    "                if not best_values_list:\n",
    "                    best_values_list = [[model_name, value] for value in model_values]\n",
    "                    worst_values_list = [[model_name, value] for value in model_values]\n",
    "                else:\n",
    "                    for index, value in enumerate(model_values):\n",
    "                        if value > best_values_list[index][1]:\n",
    "                            best_values_list[index][1] = value\n",
    "                            best_values_list[index][0] = model_name\n",
    "                        if value < worst_values_list[index][1]:\n",
    "                            worst_values_list[index][1] = value\n",
    "                            worst_values_list[index][0] = model_name\n",
    "        super().create_dataframe(best_values_list, worst_values_list)\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamonds = pd.read_csv(r'data\\processed\\diamonds_training.csv', index_col='id')\n",
    "df_predict = pd.read_csv(r'data\\processed\\diamonds_testing.csv', index_col='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ridge(df):\n",
    "    '''Uses ridge to impute a few outliers from the depth (millimeters) column of the diamonds dataframe'''\n",
    "    q3, q1 = np.percentile(df['depth (millimeters)'], [75, 25])\n",
    "    iqr = q3 - q1\n",
    "    y_test = df[(df['depth (millimeters)'] > q3 + 1.5*iqr) | (df['depth (millimeters)'] < q1 - 1.5*iqr)]['depth (millimeters)']\n",
    "    y_train = df.drop(y_test.index)['depth (millimeters)']\n",
    "    X_train = df.drop(y_test.index)[['weight (carat)', 'lenght (millimeters)', 'width (millimeters)']]\n",
    "    X_test = df[(df['depth (millimeters)'] > q3 + 1.5*iqr) | (df['depth (millimeters)'] < q1 - 1.5*iqr)][['weight (carat)', 'lenght (millimeters)', 'width (millimeters)']]\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    df_depth = pd.DataFrame(data={'Original depth': y_test, 'Predicted depth': y_pred})\n",
    "    for index in df_depth.index:\n",
    "        df.loc[index, 'depth (millimeters)'] = df_depth.loc[index, 'Predicted depth']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['width (millimeters)', 'lenght (millimeters)', 'depth (millimeters)']\n",
    "df = df_diamonds.copy()\n",
    "for index, col in enumerate(cols):\n",
    "    cols.pop(index)\n",
    "    df_train = df.drop(df[(df[cols[0]] == 0) | (df[cols[1]] == 0) | (df[col] == 0)].index)\n",
    "    df_test = df[df[col] == 0]\n",
    "    X_train = df_train.drop(columns=col)\n",
    "    y_train = df_train[col]\n",
    "    x_test = df_test.drop(columns=col)\n",
    "    y_test = df_test[col]\n",
    "    cols.append(col)\n",
    "    ridge = Ridge()\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(x_test)\n",
    "    df[col + ' ridge'] = 0\n",
    "    df.loc[df[col] == 0, col + ' ridge'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight (carat)</th>\n",
       "      <th>cut quality</th>\n",
       "      <th>color quality</th>\n",
       "      <th>clarity quality</th>\n",
       "      <th>depth (percentage)</th>\n",
       "      <th>table (percentage)</th>\n",
       "      <th>lenght (millimeters)</th>\n",
       "      <th>width (millimeters)</th>\n",
       "      <th>depth (millimeters)</th>\n",
       "      <th>price</th>\n",
       "      <th>width (millimeters) ridge</th>\n",
       "      <th>depth (millimeters) ridge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.68</td>\n",
       "      <td>6.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.46</td>\n",
       "      <td>4.04</td>\n",
       "      <td>9.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.72</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.74</td>\n",
       "      <td>3.54</td>\n",
       "      <td>7.983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.12</td>\n",
       "      <td>8.371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.82</td>\n",
       "      <td>6.588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40450</th>\n",
       "      <td>0.42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.82</td>\n",
       "      <td>2.98</td>\n",
       "      <td>6.551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40451</th>\n",
       "      <td>0.53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.18</td>\n",
       "      <td>3.22</td>\n",
       "      <td>7.382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40452</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40453</th>\n",
       "      <td>1.01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.96</td>\n",
       "      <td>8.726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40454</th>\n",
       "      <td>1.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.14</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40455 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight (carat)  cut quality  color quality  clarity quality  \\\n",
       "id                                                                   \n",
       "0                0.30          3.0            6.0              1.0   \n",
       "1                1.01          4.0            5.0              5.0   \n",
       "2                0.72          4.0            4.0              3.0   \n",
       "3                1.08          2.0            3.0              1.0   \n",
       "4                0.36          3.0            3.0              4.0   \n",
       "...               ...          ...            ...              ...   \n",
       "40450            0.42          3.0            6.0              1.0   \n",
       "40451            0.53          3.0            3.0              3.0   \n",
       "40452            0.80          1.0            3.0              1.0   \n",
       "40453            1.01          2.0            4.0              3.0   \n",
       "40454            1.30          3.0            1.0              3.0   \n",
       "\n",
       "       depth (percentage)  table (percentage)  lenght (millimeters)  \\\n",
       "id                                                                    \n",
       "0                    62.4                58.0                  4.31   \n",
       "1                    62.7                56.0                  6.42   \n",
       "2                    61.8                59.0                  5.71   \n",
       "3                    63.2                57.0                  6.54   \n",
       "4                    62.3                59.0                  4.50   \n",
       "...                   ...                 ...                   ...   \n",
       "40450                62.1                59.0                  4.78   \n",
       "40451                62.0                58.0                  5.21   \n",
       "40452                62.8                58.0                  5.86   \n",
       "40453                61.5                57.0                  6.40   \n",
       "40454                60.1                58.0                  7.10   \n",
       "\n",
       "       width (millimeters)  depth (millimeters)  price  \\\n",
       "id                                                       \n",
       "0                     4.28                 2.68  6.353   \n",
       "1                     6.46                 4.04  9.183   \n",
       "2                     5.74                 3.54  7.983   \n",
       "3                     6.50                 4.12  8.371   \n",
       "4                     4.55                 2.82  6.588   \n",
       "...                    ...                  ...    ...   \n",
       "40450                 4.82                 2.98  6.551   \n",
       "40451                 5.18                 3.22  7.382   \n",
       "40452                 5.90                 3.69  7.768   \n",
       "40453                 6.48                 3.96  8.726   \n",
       "40454                 7.14                 4.28  8.771   \n",
       "\n",
       "       width (millimeters) ridge  depth (millimeters) ridge  \n",
       "id                                                           \n",
       "0                            0.0                        0.0  \n",
       "1                            0.0                        0.0  \n",
       "2                            0.0                        0.0  \n",
       "3                            0.0                        0.0  \n",
       "4                            0.0                        0.0  \n",
       "...                          ...                        ...  \n",
       "40450                        0.0                        0.0  \n",
       "40451                        0.0                        0.0  \n",
       "40452                        0.0                        0.0  \n",
       "40453                        0.0                        0.0  \n",
       "40454                        0.0                        0.0  \n",
       "\n",
       "[40455 rows x 12 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62be4b4d7aada9f05487a097e316e83dc3ceda15568e9d0ea281b513767b88d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
