{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if str(os.getcwdb()[-3:]).split(\"'\")[1] != 'src':\n",
    "    os.chdir(os.path.dirname(os.getcwdb()))\n",
    "\n",
    "from utils.cleansing import Cleansing\n",
    "from utils.modeling import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamonds = pd.read_csv(r'data\\processed\\diamonds_train_1.csv', index_col='id')\n",
    "df_predict = pd.read_csv(r'data\\processed\\diamonds_test_1.csv', index_col='id')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consideraciones\n",
    "- Se localiza el tema en Kaggle: https://www.kaggle.com/datasets/shivam2503/diamonds\n",
    "- Se empieza a trabajar con ese \"dataset\" (ver los archivos marcados como \"UNUSED\" y \"no competition\")\n",
    "- Se detecta que existe una competición, si bien ya ha terminado: https://www.kaggle.com/competitions/diamonds-part-datamad0122/overview\n",
    "- Se elige trabajar con los archivos de la competición, cuyas únicas diferencias es que hay un \"train\" y un \"test\", y que la variable \"target\" está escalada\n",
    "- El \"dataset\" final es un listado de diamantes con sus características, y el objetivo es predecir el precio\n",
    "- Se comparará lo obtenido con los resultados de la competición"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "- Los pasos de esta primera parte se detallan de forma más pormenorizada, paso a paso, en el \"notebook\" titulado \"EDA_diamonds\"\n",
    "- En ese \"notebook\" se hacen dos cosas:\n",
    "1) Modificaciones esenciales; se liquidan duplicados, se cambia el nombre de las columnas y se pasan las categóricas a numéricas, tanto del \"train\" como del \"test\".\n",
    "\n",
    "2) Modificaciones opcionales; se detectan y ponen a prueba las posibles modifiaciones que llevar a cabo con el \"dataframe\" de entrenamiento con tal de mejorar el resultado de los modelos. Los resortes de dichos cambios se guardan en forma de funciones (cuando son exclusivos de este proyecto) o clases (cuando es razonable guardarlos para análisis futuros), que se irán llamando a continuación según convenga."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelaje\n",
    "- Se importan los \"dataframes\" con las modificaciones esenciales\n",
    "- Se van intercalando modificiaciones opcionales y diversos modelos hasta dar con el mejor resultado\n",
    "- Los modelos de prueban en este \"notebook\" para mayor comodidad, pero se ejecutan sin detallarse en \"train.py\", desde donde se guardan en la carpeta \"model\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ronda 1\n",
    "- Para la primera fase, se prueban todos los modelos sin hacer ninguna modificación adicional\n",
    "- En esta primera ronda están más detallados los usos de la clase \"Model\" para que sirva como ejemplo\n",
    "- Como es de esperar, los resultados no son muy buenos\n",
    "- Pueden compararse con los de la competición de Kaggle: https://www.kaggle.com/competitions/diamonds-part-datamad0122/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la instancia de la clase \"Model\" con la columna \"price\" como \"target\"\n",
    "round_1 = Model(df_diamonds, 'price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separa el \"dataframe\" con los parámetros por defecto. Se guardan las porciones por si acaso\n",
    "X_train, X_test, y_train, y_test = round_1.split_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Regression: using best of KFold --\n",
      "Starting LinearRegression:\n",
      "- LinearRegression done in 0.43 sec(s). Total time: 0.43\n",
      "Starting Ridge:\n",
      "- Ridge done in 0.27 sec(s). Total time: 0.7\n",
      "Starting DecisionTreeRegressor:\n",
      "- DecisionTreeRegressor done in 4.69 sec(s). Total time: 5.39\n",
      "Starting KNeighborsRegressor:\n",
      "- KNeighborsRegressor done in 11.25 sec(s). Total time: 16.64\n",
      "Starting RandomForestRegressor:\n",
      "- RandomForestRegressor done in 264.61 sec(s). Total time: 281.25\n",
      "Starting SVR:\n",
      "- SVR done in 388.98 sec(s). Total time: 670.23\n"
     ]
    }
   ],
   "source": [
    "# Se solicitan 10 \"folds\", del cual se usará el mejor para comparar los modelos y ver cuál llega más lejos\n",
    "# Como la \"target\" es de regresión, la instancia seleccionará automáticamente \"KFold\" en lugar de \"StratifiedFold\"\n",
    "round_1_dict = round_1.apply_models(kfolds_num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.1751789 , 8.94534424, 7.94609508, ..., 9.13303572, 8.78005708,\n",
       "         8.22465851]),\n",
       "  'model': LinearRegression()},\n",
       " 'Ridge': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.17485364, 8.94499768, 7.94593798, ..., 9.13327901, 8.78003269,\n",
       "         8.22426296]),\n",
       "  'model': Ridge()},\n",
       " 'DecisionTreeRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.009, 9.24 , 8.107, ..., 9.343, 8.951, 8.328]),\n",
       "  'model': DecisionTreeRegressor()},\n",
       " 'KNeighborsRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.2228, 9.072 , 8.0682, ..., 9.09  , 8.7678, 8.706 ]),\n",
       "  'model': KNeighborsRegressor()},\n",
       " 'RandomForestRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.21693, 9.1298 , 8.13663, ..., 9.27139, 8.90605, 8.34692]),\n",
       "  'model': RandomForestRegressor()},\n",
       " 'SVR': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.1605641 , 8.95509437, 7.9788505 , ..., 9.22422321, 8.8675288 ,\n",
       "         8.20764258]),\n",
       "  'model': SVR()}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se guardan los resultados, así como el modelo entrenado, en un diccionario\n",
    "round_1_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.1751789 , 8.94534424, 7.94609508, ..., 9.13303572, 8.78005708,\n",
       "         8.22465851]),\n",
       "  'model': LinearRegression(),\n",
       "  'metrics': {'rmse': 0.222037823248969,\n",
       "   'mse': 0.0493007949531404,\n",
       "   'mae': 0.12289980638635319,\n",
       "   'r2_score': 0.9529090797126748,\n",
       "   'mape': 0.01587291534328809}},\n",
       " 'Ridge': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.17485364, 8.94499768, 7.94593798, ..., 9.13327901, 8.78003269,\n",
       "         8.22426296]),\n",
       "  'model': Ridge(),\n",
       "  'metrics': {'rmse': 0.2219231703319744,\n",
       "   'mse': 0.04924989353019452,\n",
       "   'mae': 0.1229616970889257,\n",
       "   'r2_score': 0.9529576995138916,\n",
       "   'mape': 0.015880870501013333}},\n",
       " 'DecisionTreeRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.009, 9.24 , 8.107, ..., 9.343, 8.951, 8.328]),\n",
       "  'model': DecisionTreeRegressor(),\n",
       "  'metrics': {'rmse': 0.13017717461523345,\n",
       "   'mse': 0.016946096790804978,\n",
       "   'mae': 0.08879727280217517,\n",
       "   'r2_score': 0.9838135004939457,\n",
       "   'mape': 0.01143203693467865}},\n",
       " 'KNeighborsRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.2228, 9.072 , 8.0682, ..., 9.09  , 8.7678, 8.706 ]),\n",
       "  'model': KNeighborsRegressor(),\n",
       "  'metrics': {'rmse': 0.18386510856104435,\n",
       "   'mse': 0.03380637814616462,\n",
       "   'mae': 0.1351555573865041,\n",
       "   'r2_score': 0.9677089698046988,\n",
       "   'mape': 0.01780637784629908}},\n",
       " 'RandomForestRegressor': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.21693, 9.1298 , 8.13663, ..., 9.27139, 8.90605, 8.34692]),\n",
       "  'model': RandomForestRegressor(),\n",
       "  'metrics': {'rmse': 0.09885719104780755,\n",
       "   'mse': 0.00977274422186272,\n",
       "   'mae': 0.06739843083134213,\n",
       "   'r2_score': 0.9906653124036321,\n",
       "   'mape': 0.008718657624230406}},\n",
       " 'SVR': {'test': array([8.069, 9.093, 8.297, ..., 9.234, 8.818, 8.368]),\n",
       "  'prediction': array([8.1605641 , 8.95509437, 7.9788505 , ..., 9.22422321, 8.8675288 ,\n",
       "         8.20764258]),\n",
       "  'model': SVR(),\n",
       "  'metrics': {'rmse': 0.2090635876352297,\n",
       "   'mse': 0.04370758367491336,\n",
       "   'mae': 0.12747711693978012,\n",
       "   'r2_score': 0.9582515790923197,\n",
       "   'mape': 0.01652290177663025}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acto seguido, se miran las métricas\n",
    "round_1_metrics = round_1.evaluate_metrics(round_1_dict)\n",
    "\n",
    "round_1_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <th>SVR</th>\n",
       "      <th>BEST</th>\n",
       "      <th>WORST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.222038</td>\n",
       "      <td>0.221923</td>\n",
       "      <td>0.130177</td>\n",
       "      <td>0.183865</td>\n",
       "      <td>0.098857</td>\n",
       "      <td>0.209064</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.016946</td>\n",
       "      <td>0.033806</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.043708</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.122962</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.135156</td>\n",
       "      <td>0.067398</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>0.952909</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.983814</td>\n",
       "      <td>0.967709</td>\n",
       "      <td>0.990665</td>\n",
       "      <td>0.958252</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.015881</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LinearRegression     Ridge  DecisionTreeRegressor  \\\n",
       "rmse              0.222038  0.221923               0.130177   \n",
       "mse               0.049301  0.049250               0.016946   \n",
       "mae               0.122900  0.122962               0.088797   \n",
       "r2_score          0.952909  0.952958               0.983814   \n",
       "mape              0.015873  0.015881               0.011432   \n",
       "\n",
       "          KNeighborsRegressor  RandomForestRegressor       SVR  \\\n",
       "rmse                 0.183865               0.098857  0.209064   \n",
       "mse                  0.033806               0.009773  0.043708   \n",
       "mae                  0.135156               0.067398  0.127477   \n",
       "r2_score             0.967709               0.990665  0.958252   \n",
       "mape                 0.017806               0.008719  0.016523   \n",
       "\n",
       "                           BEST                WORST  \n",
       "rmse      RandomForestRegressor     LinearRegression  \n",
       "mse       RandomForestRegressor     LinearRegression  \n",
       "mae         KNeighborsRegressor  KNeighborsRegressor  \n",
       "r2_score  RandomForestRegressor     LinearRegression  \n",
       "mape        KNeighborsRegressor  KNeighborsRegressor  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para mejor visualización, se ponen en un \"dataframe\"\n",
    "# Las predicciones no son muy buenas, pero \"RandomForest\" va en cabeza\n",
    "round_1.create_dataframe(round_1_metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ronda 2\n",
    "- Se repite la ronda 1, pero esta vez se escalan las variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62be4b4d7aada9f05487a097e316e83dc3ceda15568e9d0ea281b513767b88d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
