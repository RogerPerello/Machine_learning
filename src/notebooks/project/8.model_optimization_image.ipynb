{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "\n",
    "if str(os.getcwdb()[-3:]).split(\"'\")[1] != 'src':\n",
    "    for _ in range(2):\n",
    "        os.chdir(os.path.dirname(os.getcwdb()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>weight (carat)</th>\n",
       "      <th>cut quality</th>\n",
       "      <th>color quality</th>\n",
       "      <th>clarity quality</th>\n",
       "      <th>depth (percentage)</th>\n",
       "      <th>length (millimeters)</th>\n",
       "      <th>width (millimeters)</th>\n",
       "      <th>depth (millimeters)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1638147</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.553191</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1612606</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.900662</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1638140</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.813522</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1536093</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.720524</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643527</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.141612</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.42</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  weight (carat)  cut quality  color quality  clarity quality  \\\n",
       "0  1638147            0.55          4.0            5.0              1.0   \n",
       "1  1612606            0.51          4.0            2.0              3.0   \n",
       "2  1638140            0.50          4.0            2.0              3.0   \n",
       "3  1536093            0.53          4.0            6.0              2.0   \n",
       "4  1643527            0.52          4.0            1.0              6.0   \n",
       "\n",
       "   depth (percentage)  length (millimeters)  width (millimeters)  \\\n",
       "0           62.553191                  5.05                 4.35   \n",
       "1           64.900662                  4.71                 4.35   \n",
       "2           62.813522                  4.91                 4.26   \n",
       "3           65.720524                  4.70                 4.46   \n",
       "4           65.141612                  4.76                 4.42   \n",
       "\n",
       "   depth (millimeters)  \n",
       "0                 2.94  \n",
       "1                 2.94  \n",
       "2                 2.88  \n",
       "3                 3.01  \n",
       "4                 2.99  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_images_path = r'data\\processed\\images'\n",
    "df_images_data = pd.read_csv(r'data\\processed\\images_data_processed.csv')\n",
    "\n",
    "df_images_data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tamaño de las imágenes\n",
    "\n",
    "- Se modifican los píxeles de cada imagen, de 300 a 224, para que puedan encajar en el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in glob.glob(processed_images_path+'/*.jpg'):\n",
    "    with Image.open(image_path) as image:\n",
    "        image = image.resize((224, 224))\n",
    "        image.save(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se comprueba que el cambio ha surtido efecto\n",
    "for image in glob.glob(processed_images_path+'/*.jpg'):\n",
    "    image_matrix = cv2.imread(image)\n",
    "    break\n",
    "\n",
    "image_matrix.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Split\"\n",
    "\n",
    "- Se separa el \"dataframe\" en \"train\" y \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>weight (carat)</th>\n",
       "      <th>cut quality</th>\n",
       "      <th>color quality</th>\n",
       "      <th>clarity quality</th>\n",
       "      <th>depth (percentage)</th>\n",
       "      <th>length (millimeters)</th>\n",
       "      <th>width (millimeters)</th>\n",
       "      <th>depth (millimeters)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1638147.jpg</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.553191</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1612606.jpg</td>\n",
       "      <td>0.51</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.900662</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1638140.jpg</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.813522</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1536093.jpg</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.720524</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1643527.jpg</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.141612</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.42</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  weight (carat)  cut quality  color quality  clarity quality  \\\n",
       "0  1638147.jpg            0.55          4.0            5.0              1.0   \n",
       "1  1612606.jpg            0.51          4.0            2.0              3.0   \n",
       "2  1638140.jpg            0.50          4.0            2.0              3.0   \n",
       "3  1536093.jpg            0.53          4.0            6.0              2.0   \n",
       "4  1643527.jpg            0.52          4.0            1.0              6.0   \n",
       "\n",
       "   depth (percentage)  length (millimeters)  width (millimeters)  \\\n",
       "0           62.553191                  5.05                 4.35   \n",
       "1           64.900662                  4.71                 4.35   \n",
       "2           62.813522                  4.91                 4.26   \n",
       "3           65.720524                  4.70                 4.46   \n",
       "4           65.141612                  4.76                 4.42   \n",
       "\n",
       "   depth (millimeters)  \n",
       "0                 2.94  \n",
       "1                 2.94  \n",
       "2                 2.88  \n",
       "3                 3.01  \n",
       "4                 2.99  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_data['Id'] = df_images_data['Id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "df_images_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>weight (carat)</th>\n",
       "      <th>cut quality</th>\n",
       "      <th>color quality</th>\n",
       "      <th>clarity quality</th>\n",
       "      <th>depth (percentage)</th>\n",
       "      <th>length (millimeters)</th>\n",
       "      <th>width (millimeters)</th>\n",
       "      <th>depth (millimeters)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>1798065.jpg</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.825319</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.11</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1786532.jpg</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.371571</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1634076.jpg</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.947469</td>\n",
       "      <td>5.43</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>1643658.jpg</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.773973</td>\n",
       "      <td>7.13</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>1769140.jpg</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.323671</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.18</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  weight (carat)  cut quality  color quality  \\\n",
       "3778  1798065.jpg            0.50          4.0            0.0   \n",
       "978   1786532.jpg            0.31          4.0            5.0   \n",
       "251   1634076.jpg            0.80          4.0            1.0   \n",
       "2154  1643658.jpg            0.59          4.0            3.0   \n",
       "4099  1769140.jpg            0.50          4.0            5.0   \n",
       "\n",
       "      clarity quality  depth (percentage)  length (millimeters)  \\\n",
       "3778              3.0           61.825319                  5.08   \n",
       "978               5.0           51.371571                  4.89   \n",
       "251               2.0           64.947469                  5.43   \n",
       "2154              5.0           47.773973                  7.13   \n",
       "4099              1.0           59.323671                  5.17   \n",
       "\n",
       "      width (millimeters)  depth (millimeters)  \n",
       "3778                 5.11                 3.15  \n",
       "978                  3.13                 2.06  \n",
       "251                  5.04                 3.40  \n",
       "2154                 4.55                 2.79  \n",
       "4099                 5.18                 3.07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_images_data['Id'], df_images_data.drop(columns='Id'), train_size=0.8, random_state=42)\n",
    "\n",
    "df_train = pd.concat((X_train, y_train), axis=1)\n",
    "df_test = pd.concat((X_test, y_test), axis=1)\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Data augmentation\"\n",
    "\n",
    "- Se crea una variable para generar imágenes en diferentes posiciones para que el modelo disponga del mismo diamante colocado de modos distintos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se establecen las variables para crear nuevos diamantes y para seleccionar el tamaño de imagen correcto\n",
    "data_augmentation = ImageDataGenerator(rotation_range=20,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        preprocessing_function=preprocess_input,\n",
    "                                        validation_split=0.1\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3254 validated image filenames.\n",
      "Found 361 validated image filenames.\n",
      "Found 904 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Se crean tres \"generators\" con los datos aumentados (entrenamiento, validación y \"test\")\n",
    "train_generator = data_augmentation.flow_from_dataframe(dataframe=df_train,\n",
    "                                                        directory=processed_images_path,\n",
    "                                                        target_size=(224, 224),\n",
    "                                                        class_mode='raw',\n",
    "                                                        shuffle=False,\n",
    "                                                        x_col='Id',\n",
    "                                                        y_col=list(df_images_data.columns[1:]),\n",
    "                                                        seed=42,\n",
    "                                                        subset='training'\n",
    "                                                        )\n",
    "\n",
    "validation_generator = data_augmentation.flow_from_dataframe(dataframe=df_train,\n",
    "                                                                directory=processed_images_path,\n",
    "                                                                target_size=(224, 224),\n",
    "                                                                class_mode='raw',\n",
    "                                                                shuffle=False,\n",
    "                                                                x_col='Id',\n",
    "                                                                y_col=list(df_images_data.columns[1:]),\n",
    "                                                                seed=42,\n",
    "                                                                subset='validation'\n",
    "                                                                )\n",
    "\n",
    "test_generator = data_augmentation.flow_from_dataframe(dataframe=df_test,\n",
    "                                                        directory=processed_images_path,\n",
    "                                                        target_size=(224, 224),\n",
    "                                                        class_mode='raw',\n",
    "                                                        shuffle=False,\n",
    "                                                        x_col='Id',\n",
    "                                                        y_col=list(df_images_data.columns[1:]),\n",
    "                                                        seed=42,\n",
    "                                                        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelaje: entreno solo con imágenes\n",
    "\n",
    "- Se elige VGG16 por las siguientes razones:\n",
    "\n",
    "1) Es popular y se ha utilizado con éxito en investigación\n",
    "2) Es relativamente fácil utilizarlo para problemas de regresión\n",
    "3) Tiene un buen rendimiento\n",
    "4) Trabaja con RGB, y el color de los diamantes es importante\n",
    "5) Utiliza un tamaño de 224x224, y se ha visto que a partir de 150 componentes se obtiene toda la información necesaria\n",
    "6) Otros como ResNet, Inception y EfficientNet son más modernos y podrían dar mejores resultados, pero el coste computacional podría elevarse mucho, lo que con toda probabilidad no valdría la pena para un \"dataset\" tan pequeño\n",
    "7) Se ve durante el \"train\" que, a pesar de ser pocas las fotos, dado que son muchas las variables a predecir y se trata de un problema de regressión, el modelo es extremadamente lento. Por tanto, es inviable probar con los que son mas complejos, pues tardarían incluso más\n",
    "\n",
    "- El modelo sufre \"overfitting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga el modelo sin la capa superior\n",
    "base_model = VGG16(include_top=False, input_shape=((224, 224, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se congelan las capas base para que no se entrenen al tunear parámetros, sino que queden igual\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una nueva capa superior\n",
    "top_model = Flatten()(base_model.output)\n",
    "top_model = Dense(1024, activation='relu')(top_model)\n",
    "top_model = Dense(512, activation='relu')(top_model)\n",
    "output_layer = Dense(8, activation='linear')(top_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se tunea el modelo con la capa nueva\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se compila y se le pone un optimizador\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 2804s 27s/step - loss: 10.4851 - val_loss: 9.5512\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 2877s 28s/step - loss: 9.1146 - val_loss: 8.5894\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 2878s 28s/step - loss: 8.1391 - val_loss: 7.5508\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 2717s 27s/step - loss: 7.2157 - val_loss: 6.8317\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 2716s 27s/step - loss: 6.3320 - val_loss: 5.6712\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 2717s 27s/step - loss: 4.8076 - val_loss: 3.7442\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 2717s 27s/step - loss: 2.6211 - val_loss: 1.7659\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 2716s 27s/step - loss: 1.5800 - val_loss: 1.5317\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 2716s 27s/step - loss: 1.5183 - val_loss: 1.5358\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 2716s 27s/step - loss: 1.5198 - val_loss: 1.5309\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 2752s 27s/step - loss: 1.5177 - val_loss: 1.5320\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 3074s 30s/step - loss: 1.5172 - val_loss: 1.5341\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 2944s 29s/step - loss: 1.5176 - val_loss: 1.5365\n"
     ]
    }
   ],
   "source": [
    "# Se entrena el modelo con \"early stopping\"\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[early_stop]\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 737s 25s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight (carat)': {'mse': 0.13328463615810393,\n",
       "  'rmse': 0.3650816842271109,\n",
       "  'mae': 0.19201657599052496,\n",
       "  'r2': -0.03231979506041949,\n",
       "  'mape': 0.2904260471125496},\n",
       " 'cut quality': {'mse': 1.5673639774311583,\n",
       "  'rmse': 1.2519440791948968,\n",
       "  'mae': 0.673318200406775,\n",
       "  'r2': -0.406961150657724,\n",
       "  'mape': 99986541709004.31},\n",
       " 'color quality': {'mse': 9.108733336964494,\n",
       "  'rmse': 3.018067815169913,\n",
       "  'mae': 2.2640291167571482,\n",
       "  'r2': -0.04341466119183379,\n",
       "  'mape': 1203378812593506.2},\n",
       " 'clarity quality': {'mse': 2.28118527908921,\n",
       "  'rmse': 1.5103593211846016,\n",
       "  'mae': 1.1890781432126476,\n",
       "  'r2': -0.003099937064111158,\n",
       "  'mape': 60004893071016.19},\n",
       " 'depth (percentage)': {'mse': 59.99285645714846,\n",
       "  'rmse': 7.745505564980795,\n",
       "  'mae': 5.830462979976336,\n",
       "  'r2': -0.042812788555836256,\n",
       "  'mape': 0.10563365622823222},\n",
       " 'length (millimeters)': {'mse': 1.5820806109324623,\n",
       "  'rmse': 1.2578078593062068,\n",
       "  'mae': 0.829696589275799,\n",
       "  'r2': -0.05577155905441877,\n",
       "  'mape': 0.1395914518773208},\n",
       " 'width (millimeters)': {'mse': 0.5850010711731023,\n",
       "  'rmse': 0.7648536272863601,\n",
       "  'mae': 0.580821580464861,\n",
       "  'r2': -0.029624583854270137,\n",
       "  'mape': 0.1247105924960851},\n",
       " 'depth (millimeters)': {'mse': 0.2463897886018104,\n",
       "  'rmse': 0.4963766600091209,\n",
       "  'mae': 0.3685192521905477,\n",
       "  'r2': -0.0008672262027671351,\n",
       "  'mape': 0.12399433834178138}}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se obtienen las métricas\n",
    "metrics_dict = dict()\n",
    "for index, col in enumerate(df_images_data.columns[1:]):\n",
    "    rmse = mean_squared_error([row[index] for row in test_generator.labels], [row[index] for row in y_pred], squared=False)\n",
    "    mse = mean_squared_error([row[index] for row in test_generator.labels], [row[index] for row in y_pred])\n",
    "    mae = mean_absolute_error([row[index] for row in test_generator.labels], [row[index] for row in y_pred])\n",
    "    r2 = r2_score([row[index] for row in test_generator.labels], [row[index] for row in y_pred])\n",
    "    mape = mean_absolute_percentage_error([row[index] for row in test_generator.labels], [row[index] for row in y_pred])\n",
    "    metrics_dict[col] = {'mse': mse,\n",
    "                            'rmse': rmse,\n",
    "                            'mae': mae,\n",
    "                            'r2': r2,\n",
    "                            'mape': mape\n",
    "                         }\n",
    "\n",
    "metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original weight</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.61</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.535823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original weight  Prediction\n",
       "0               0.50    0.535823\n",
       "1               1.61    0.535823\n",
       "2               0.50    0.535823\n",
       "3               0.75    0.535823\n",
       "4               0.50    0.535823\n",
       "..               ...         ...\n",
       "899             0.50    0.535823\n",
       "900             0.50    0.535823\n",
       "901             0.31    0.535823\n",
       "902             0.50    0.535823\n",
       "903             0.50    0.535823\n",
       "\n",
       "[904 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se visualiza la predicción del peso, que es la más importante, en un \"dataframe\"\n",
    "df_weight = pd.DataFrame(data={'original weight': [row[0] for row in test_generator.labels], 'Prediction': [row[0] for row in y_pred]})\n",
    "\n",
    "df_weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelaje: entreno con imágenes y tamaño\n",
    "\n",
    "- Como las métricas anteriores no son muy buenas, se entrena el modelo pasándole, esta vez, las variables de tamaño, pues son las más sencillas de medir uno mismo en casa y, de ellas, puede extraerse también el peso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62be4b4d7aada9f05487a097e316e83dc3ceda15568e9d0ea281b513767b88d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
